{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timedelta\n",
    "%pylab inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in raw data\n",
    "\n",
    "file_names = ['incidentsQ1','incidentsQ2','incidentsQ3','incidentsQ4']\n",
    "keep_vars = ['incidentid','callstart','lat_incident','lon_incident','ccgcluster','chiefcomplaint','totaljobcycletime','dohcategory']\n",
    "incidents = pd.DataFrame(columns=keep_vars)\n",
    "\n",
    "for i in file_names:\n",
    "    globals()[str(i)] = pd.read_csv(\"CUSP London Data Dive 2019/data/Incidents/\"+i+\".csv\", parse_dates=['callstart'])[keep_vars]\n",
    "    incidents = incidents.append(globals()[str(i)])\n",
    "    \n",
    "incidents = incidents.sort_values(by=['callstart'])\n",
    "incidents = incidents.set_index('callstart')\n",
    "incidents = incidents.loc[incidents.index >= '2018-01-01 00:00:00']\n",
    "incidents = incidents.loc[incidents.index < '2019-01-01 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create time series\n",
    "\n",
    "def output_timeseries(space):\n",
    "    incidents_spatial = incidents[incidents['ccgcluster'] == space]\n",
    "    call_response = incidents_spatial[['totaljobcycletime','dohcategory']].groupby([pd.Grouper(freq='240Min'),'dohcategory']).mean()\n",
    "    call_freq = incidents_spatial[['incidentid','dohcategory']].groupby([pd.Grouper(freq='240Min'),'dohcategory']).count()\n",
    "    call_freq['Call Frequency'] = 14400 / call_freq['incidentid']\n",
    "\n",
    "    incidents_with_metrics = call_response.merge(call_freq, left_index = True, right_index = True)\n",
    "    incidents_with_metrics['Demand Index'] = incidents_with_metrics['totaljobcycletime'] / incidents_with_metrics['Call Frequency']\n",
    "    incidents_with_metricsReset = incidents_with_metrics.reset_index()\n",
    "    columnValues = ['Demand Index']\n",
    "    incident_time_series = incidents_with_metricsReset.pivot(index='callstart', columns='dohcategory', values=columnValues).fillna(0)\n",
    "    return incident_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split out spatially\n",
    "\n",
    "space_clusters = ['North Central','North East','North West','South East','South West']\n",
    "\n",
    "var_names = []\n",
    "for i in space_clusters:\n",
    "    globals()[str(i.replace(\" \", \"\"))] = output_timeseries(i)\n",
    "    var_names.append(i.replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Week on week plot\n",
    "\n",
    "# row_count = 0\n",
    "# week_count = 0\n",
    "# c1_print = []\n",
    "# fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "# for index, row in NorthCentral.iterrows():\n",
    "#     c1_print.append(row['Demand Index']['C1 '])\n",
    "#     row_count = row_count + 1\n",
    "#     if row_count == 42:\n",
    "#         row_count = 0\n",
    "#         week_count = week_count +1\n",
    "#         plt.plot(c1_print)\n",
    "#         c1_print = []\n",
    "#     if week_count == 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data for Jan - C1 - North Central\n",
    "s = NorthCentral['Demand Index']['C1 ']\n",
    "s = s.loc[s.index >= '2018-02-01 00:00:00']\n",
    "s = s.loc[s.index < '2018-05-01 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_00 = s.iloc[::6]\n",
    "# q_04 = s.iloc[1::6]\n",
    "# q_08 = s.iloc[2::6]\n",
    "q = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q.shape)\n",
    "q.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_plot(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(q, lags=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(q, order=(2,0,1))\n",
    "fit = model.fit()\n",
    "print(fit.summary())\n",
    "resids = pd.DataFrame(fit.resid)\n",
    "resids.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resids.plot(kind='KDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.append(yhat)\n",
    "obs = test[t]\n",
    "history.append(obs)\n",
    "print('predicted=%f, expected=%f' % (yhat, obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get All Data\n",
    "\n",
    "def get_data(spacial,severity,date_start,date_end):\n",
    "    s = spacial['Demand Index'][severity]\n",
    "    s = s.loc[s.index >= date_start]\n",
    "    s = s.loc[s.index < date_end]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = '2018-01-01 00:00:00'\n",
    "dt_t_start = parser.parse(train_start)\n",
    "\n",
    "train_start = '2018-04-01 00:00:00'\n",
    "dt_t_end = parser.parse(train_start)\n",
    "\n",
    "pred_end = '2018-04-01 04:00:00'\n",
    "pred_t_end = parser.parse(pred_end)\n",
    "\n",
    "q = get_data(NorthCentral,'C1 ',dt_t_start,dt_t_end)\n",
    "\n",
    "actual = get_data(NorthCentral,'C1 ',dt_t_end,pred_t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(space,severity):\n",
    "    predicted = []\n",
    "    actuals = []\n",
    "\n",
    "    train_start = '2018-01-01 00:00:00'\n",
    "    dt_t_start = parser.parse(train_start)\n",
    "\n",
    "    train_start = '2018-04-01 00:00:00'\n",
    "    dt_t_end = parser.parse(train_start)\n",
    "\n",
    "    pred_end = '2018-04-01 04:00:00'\n",
    "    pred_t_end = parser.parse(pred_end)\n",
    "\n",
    "    for i in range(0,180):\n",
    "        #Get First Two Months\n",
    "        q = get_data(space,severity,dt_t_start,dt_t_end)\n",
    "\n",
    "        #Get predicted value\n",
    "        actual = get_data(space,severity,dt_t_end,pred_t_end)\n",
    "\n",
    "        #Append Actuals\n",
    "        actuals.append(actual[0])\n",
    "\n",
    "        #Fit Model\n",
    "        model = ARIMA(q, order=(2,0,6))\n",
    "        fit = model.fit()\n",
    "        #Forecast\n",
    "        output = fit.forecast()\n",
    "        pred = output[0]\n",
    "        #Append Predicted Value\n",
    "        predicted.append(pred[0])\n",
    "\n",
    "        dt_t_start = dt_t_start + timedelta(hours=4)\n",
    "        dt_t_end = dt_t_end + timedelta(hours=4)\n",
    "        pred_t_end = pred_t_end + timedelta(hours=4)\n",
    "    \n",
    "    return predicted, actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "North East"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North East C1\n",
    "\n",
    "#Predict\n",
    "NE_C1_pred, NE_C1_actuals = train_model(NorthEast,'C1 ')\n",
    "\n",
    "#Print\n",
    "actual_log = np.log(NE_C1_actuals)+5.5\n",
    "plt.plot(actual_log)\n",
    "plt.plot(NE_C1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North East C2\n",
    "\n",
    "#Predict\n",
    "NE_C2_pred, NE_C2_actuals = train_model(NorthEast,'C2 ')\n",
    "\n",
    "#Print\n",
    "plt.plot(NE_C2_actuals)\n",
    "plt.plot(NE_C2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North East C3\n",
    "\n",
    "#Predict\n",
    "NE_C3_pred, NE_C3_actuals = train_model(NorthEast,'C3 ')\n",
    "\n",
    "#Print\n",
    "actual_log = np.log(NE_C3_actuals)\n",
    "predicted_log = np.log(NE_C3_pred)\n",
    "plt.plot(actual_log)\n",
    "plt.plot(predicted_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North East C4\n",
    "\n",
    "#Predict\n",
    "NE_C4_pred, NE_C4_actuals = train_model(NorthEast,'C4 ')\n",
    "\n",
    "#Print\n",
    "plt.plot(NE_C4_actuals)\n",
    "plt.plot(NE_C4_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South East"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#South East C1\n",
    "\n",
    "#Predict\n",
    "SE_C1_pred, SE_C1_actuals = train_model(SouthEast,'C1 ')\n",
    "\n",
    "#Print\n",
    "actual_log = np.log(SE_C1_actuals)+5.5\n",
    "plt.plot(actual_log)\n",
    "plt.plot(SE_C1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#South East C2\n",
    "\n",
    "#Predict\n",
    "SE_C2_pred, SE_C2_actuals = train_model(SouthEast,'C2 ')\n",
    "\n",
    "#Print\n",
    "plt.plot(SE_C2_actuals)\n",
    "plt.plot(SE_C2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#South East C3\n",
    "\n",
    "#Predict\n",
    "SE_C3_pred, SE_C3_actuals = train_model(SouthEast,'C3 ')\n",
    "\n",
    "#Print\n",
    "actual_log = np.log(SE_C3_actuals)\n",
    "predicted_log = np.log(SE_C3_pred)\n",
    "plt.plot(actual_log)\n",
    "plt.plot(predicted_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#South East C4\n",
    "\n",
    "#Predict\n",
    "SE_C4_pred, SE_C4_actuals = train_model(SouthEast,'C4 ')\n",
    "\n",
    "#Print\n",
    "plt.plot(SE_C4_actuals)\n",
    "plt.plot(SE_C4_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "North Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North Central C1\n",
    "\n",
    "#Predict\n",
    "NC_C1_pred, NC_C1_actuals = train_model(NorthCentral,'C1 ')\n",
    "\n",
    "#Print\n",
    "actual_log = np.log(NC_C1_actuals)+4\n",
    "plt.plot(actual_log)\n",
    "plt.plot(NC_C1_pred)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(actual_log, NC_C1_pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print\n",
    "actual_log = np.log(NC_C1_actuals)+4\n",
    "plt.plot(actual_log)\n",
    "plt.plot(NC_C1_pred)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(actual_log, NC_C1_pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North Central C2\n",
    "\n",
    "#Predict\n",
    "NC_C2_pred, NC_C2_actuals = train_model(NorthCentral,'C2 ')\n",
    "\n",
    "#Print\n",
    "plt.plot(NC_C2_actuals)\n",
    "plt.plot(NC_C2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North Central C3\n",
    "\n",
    "#Predict\n",
    "NC_C3_pred, NC_C3_actuals = train_model(NorthCentral,'C3 ')\n",
    "\n",
    "#Print\n",
    "actual_log = np.log(NC_C3_actuals)\n",
    "predicted_log = np.log(NC_C3_pred)\n",
    "plt.plot(actual_log)\n",
    "plt.plot(predicted_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North Central C4\n",
    "\n",
    "#Predict\n",
    "NC_C4_pred, NC_C4_actuals = train_model(NorthCentral,'C4 ')\n",
    "\n",
    "#Print\n",
    "plt.plot(NC_C4_actuals)\n",
    "plt.plot(NC_C4_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
